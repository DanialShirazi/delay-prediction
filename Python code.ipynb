{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data from Excel and creating initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data = pd.read_excel (r'C:\\Users\\dania\\Desktop\\data\\Input Dataset.xlsx', sheet_name='dataset',index_col=0)\n",
    "raw_data = excel_data.values[:,0:67]\n",
    "y = excel_data.label\n",
    "std_data = StandardScaler().fit_transform(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the optimal number of principal components for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.3018181818181819],\n",
       " [2, 0.1903030303030303],\n",
       " [3, 0.1333333333333333],\n",
       " [4, 0.1515151515151516],\n",
       " [5, 0.10909090909090913],\n",
       " [6, 0.11454545454545462],\n",
       " [7, 0.1260606060606061],\n",
       " [8, 0.1266666666666667],\n",
       " [9, 0.13212121212121208],\n",
       " [10, 0.13212121212121208],\n",
       " [11, 0.13818181818181818],\n",
       " [12, 0.1321212121212122],\n",
       " [13, 0.13818181818181818],\n",
       " [14, 0.13818181818181818],\n",
       " [15, 0.13818181818181818],\n",
       " [16, 0.13818181818181818],\n",
       " [17, 0.13818181818181818],\n",
       " [18, 0.14484848484848478],\n",
       " [19, 0.13818181818181818],\n",
       " [20, 0.13818181818181818]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_k_scores =[]\n",
    "for i in range (1,21):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "    data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "    data = data.assign(concrete=std_data[:,[65]])\n",
    "    data = data.assign(time=std_data[:,[66]])\n",
    "    model = SVC()\n",
    "    kernel = ['poly', 'rbf', 'sigmoid']\n",
    "    C = [ 1.0, 2.0, 3.0,5.0,10.0, 0.1, 0.01]\n",
    "    grid = dict(kernel=kernel,C=C)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                               cv=cv, scoring='accuracy',error_score=0)\n",
    "    grid_result = grid_search.fit(data, y)\n",
    "    pca_k_scores.append([i,(1-grid_result.best_score_)])\n",
    "pca_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35272727272727267,\n",
       " 0.20121212121212118,\n",
       " 0.1527272727272727,\n",
       " 0.17151515151515162,\n",
       " 0.13757575757575757,\n",
       " 0.13151515151515147,\n",
       " 0.1381818181818183,\n",
       " 0.1393939393939394,\n",
       " 0.16969696969696968,\n",
       " 0.15636363636363637,\n",
       " 0.16363636363636358,\n",
       " 0.15090909090909088,\n",
       " 0.1575757575757577,\n",
       " 0.1515151515151517,\n",
       " 0.1642424242424242,\n",
       " 0.1581818181818181,\n",
       " 0.1715151515151515,\n",
       " 0.1648484848484848,\n",
       " 0.16545454545454552,\n",
       " 0.16545454545454552]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_k_scores =[]\n",
    "for i in range (1,21):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "    data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "    data = data.assign(concrete=std_data[:,[65]])\n",
    "    data = data.assign(time=std_data[:,[66]])\n",
    "    model = KNeighborsClassifier()\n",
    "    n_neighbors = range(1, 21,2)                 \n",
    "    leaf_size = [10, 20, 30, 50]\n",
    "    metric = ['euclidean','minkowski','manhattan']\n",
    "    grid = dict(n_neighbors=n_neighbors,metric=metric, leaf_size=leaf_size)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid,\n",
    "                           n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "    grid_result = grid_search.fit(data, y)\n",
    "    pca_k_scores.append(1-grid_result.best_score_)\n",
    "pca_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3284848484848484,\n",
       " 0.1884848484848486,\n",
       " 0.18060606060606055,\n",
       " 0.18727272727272726,\n",
       " 0.16909090909090907,\n",
       " 0.18848484848484837,\n",
       " 0.21272727272727276,\n",
       " 0.19454545454545447,\n",
       " 0.19999999999999984,\n",
       " 0.20060606060606057,\n",
       " 0.19333333333333336,\n",
       " 0.20666666666666655,\n",
       " 0.22484848484848485,\n",
       " 0.21393939393939398,\n",
       " 0.21939393939393925,\n",
       " 0.23272727272727267,\n",
       " 0.22545454545454535,\n",
       " 0.20666666666666667,\n",
       " 0.20181818181818179,\n",
       " 0.22606060606060607]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_k_scores =[]\n",
    "for i in range (1,21):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "    data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "    data = data.assign(concrete=std_data[:,[65]])\n",
    "    data = data.assign(time=std_data[:,[66]])\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    n_estimators = [50, 100, 120, 200]\n",
    "    max_features = ['sqrt', 'log2']\n",
    "    max_depth = [2,6,8,10]\n",
    "    grid = dict(n_estimators=n_estimators,\n",
    "                max_features=max_features,max_depth=max_depth)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='accuracy',error_score=0)\n",
    "    grid_result = grid_search.fit(data, y)\n",
    "    pca_k_scores.append(1-grid_result.best_score_)\n",
    "pca_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38943562610229276,\n",
       " 0.17684784351451033,\n",
       " 0.14100529100529102,\n",
       " 0.16134038800705475,\n",
       " 0.13107583774250442,\n",
       " 0.12469135802469133,\n",
       " 0.12469135802469133,\n",
       " 0.12358024691358027,\n",
       " 0.14007054673721342,\n",
       " 0.1852380952380952,\n",
       " 0.17786596119929454,\n",
       " 0.17827160493827165,\n",
       " 0.17206349206349203,\n",
       " 0.18564373897707231,\n",
       " 0.18564373897707231,\n",
       " 0.18564373897707231,\n",
       " 0.18564373897707231,\n",
       " 0.1925573192239859,\n",
       " 0.1925573192239859,\n",
       " 0.1925573192239859]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_k_scores =[]\n",
    "for i in range (1,21):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "    data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "    data = data.assign(concrete=std_data[:,[65]])\n",
    "    data = data.assign(time=std_data[:,[66]])\n",
    "    model = GaussianNB()\n",
    "    var_smoothing= np.logspace(0,-9, num=5)\n",
    "    grid = dict(var_smoothing=var_smoothing)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                               cv=cv, scoring='f1_macro',error_score=0)\n",
    "    grid_result = grid_search.fit(data, y)\n",
    "    pca_k_scores.append(1-grid_result.best_score_)\n",
    "pca_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4181818181818181,\n",
       " 0.1581818181818181,\n",
       " 0.16303030303030297,\n",
       " 0.18181818181818177,\n",
       " 0.17515151515151517,\n",
       " 0.17575757575757567,\n",
       " 0.19939393939393923,\n",
       " 0.18787878787878776,\n",
       " 0.19393939393939374,\n",
       " 0.21939393939393925,\n",
       " 0.21939393939393914,\n",
       " 0.21878787878787864,\n",
       " 0.21939393939393925,\n",
       " 0.23212121212121195,\n",
       " 0.23212121212121195,\n",
       " 0.22606060606060596,\n",
       " 0.22606060606060596,\n",
       " 0.23272727272727267,\n",
       " 0.22545454545454535,\n",
       " 0.22060606060606058]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_k_scores =[]\n",
    "for i in range (1,21):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "    data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "    data = data.assign(concrete=std_data[:,[65]])\n",
    "    data = data.assign(time=std_data[:,[66]])\n",
    "    model = xgb.XGBClassifier(objective='multi:softmax')\n",
    "    subsample = [0.5, 0.75]\n",
    "    colsample_bytree = [0.75, 1]\n",
    "    min_child_weight= [0.5, 1]\n",
    "    max_depth =[2,6]\n",
    "    learning_rate = [0.1]\n",
    "    n_estimators = [1000, 2000]\n",
    "    grid = dict(subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                min_child_weight=min_child_weight,max_depth=max_depth,\n",
    "                learning_rate=learning_rate,n_estimators=n_estimators)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='accuracy',error_score=0)\n",
    "    grid_result = grid_search.fit(data, y)\n",
    "    pca_k_scores.append(1-grid_result.best_score_)\n",
    "pca_k_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction with PCA and creating the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "pca.explained_variance_ratio_\n",
    "data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "data = data.assign(concrete=std_data[:,[65]])\n",
    "data = data.assign(time=std_data[:,[66]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters of base classifiers using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.848137 using {'leaf_size': 10, 'metric': 'euclidean', 'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "n_neighbors = range(1, 21,2)     \n",
    "leaf_size = [10, 20, 30, 50]\n",
    "metric = ['euclidean','minkowski','manhattan']\n",
    "grid = dict(n_neighbors=n_neighbors,metric=metric, leaf_size=leaf_size)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid,\n",
    "                           n_jobs=-1, cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.884374 using {'C': 1.0, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "C = [ 1.0, 2.0, 3.0, 5.0, 10.0, 0.1, 0.01]\n",
    "grid = dict(kernel=kernel,C=C)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.802257 using {'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "n_estimators = [50, 100, 120, 200]\n",
    "max_features = ['sqrt', 'log2']\n",
    "max_depth = [2,6,8,10]\n",
    "grid = dict(n_estimators=n_estimators,\n",
    "            max_features=max_features,max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.868924 using {'var_smoothing': 0.005623413251903491}\n"
     ]
    }
   ],
   "source": [
    "model =  GaussianNB()\n",
    "var_smoothing= np.logspace(0,-9, num=5)\n",
    "grid = dict(var_smoothing=var_smoothing)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.805450 using {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 2, 'min_child_weight': 0.5, 'n_estimators': 2000, 'subsample': 0.75}\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective='multi:softmax')\n",
    "subsample = [0.5, 0.75, 1]\n",
    "colsample_bytree = [0.5, 0.75, 1]\n",
    "min_child_weight= [0.5, 1, 5]\n",
    "max_depth =[2,6,8]\n",
    "learning_rate = [0.1, 0.01, 0.05]\n",
    "n_estimators = [200, 500, 1000, 2000]\n",
    "grid = dict(subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "            min_child_weight=min_child_weight,max_depth=max_depth,\n",
    "            learning_rate=learning_rate,n_estimators=n_estimators)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training base classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(metric= 'euclidean', n_neighbors= 3, leaf_size=10)\n",
    "model_svm = SVC(C= 1.0, kernel='sigmoid')\n",
    "model_rf = RandomForestClassifier(random_state=1, max_depth=8 , max_features='sqrt', n_estimators=200)\n",
    "model_nb = GaussianNB(var_smoothing= 0.0056)\n",
    "model_xgb = xgb.XGBClassifier(objective='multi:softmax', colsample_bytree=1, learning_rate= 0.1,\n",
    "                              max_depth= 2, min_child_weight= 0.5, n_estimators= 2000, subsample= 0.75)\n",
    "models=[(\"knn\", model_knn),(\"svm\",model_svm),(\"rf\", model_rf),(\"nb\",model_nb),(\"xgb\",model_xgb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding and tuning the best meta learner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.908131 using {'final_estimator__leaf_size': 10, 'final_estimator__metric': 'manhattan', 'final_estimator__n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "model_stack =  KNeighborsClassifier()\n",
    "model = StackingClassifier(estimators=models, final_estimator=model_stack)\n",
    "n_neighbors = range(1, 21,2)                 \n",
    "metric = ['euclidean','minkowski','manhattan']\n",
    "leaf_size = [10, 20, 30, 50]\n",
    "grid = dict(final_estimator__n_neighbors=n_neighbors,final_estimator__metric=metric, final_estimator__leaf_size=leaf_size)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid,\n",
    "                           n_jobs=-1, cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.914903 using {'final_estimator__C': 0.1, 'final_estimator__kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "model_stack =  SVC()\n",
    "model = StackingClassifier(estimators=models, final_estimator=model_stack)\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "C = [ 1.0, 2.0, 3.0, 5.0, 10.0, 0.1, 0.01]\n",
    "grid = dict(final_estimator__kernel=kernel,final_estimator__C=C)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid,\n",
    "                           n_jobs=-1, cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.856808 using {'final_estimator__max_depth': 2, 'final_estimator__max_features': 'sqrt', 'final_estimator__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "model_stack =  RandomForestClassifier(random_state=1)\n",
    "model = StackingClassifier(estimators=models, final_estimator=model_stack)\n",
    "n_estimators = [50, 100, 120, 200]\n",
    "max_features = ['sqrt', 'log2']\n",
    "max_depth = [2,6,8,10]\n",
    "grid = dict(final_estimator__n_estimators=n_estimators,\n",
    "            final_estimator__max_features=max_features,final_estimator__max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid,\n",
    "                           n_jobs=-1, cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.855379 using {'final_estimator__colsample_bytree': 0.75, 'final_estimator__learning_rate': 0.1, 'final_estimator__max_depth': 2, 'final_estimator__min_child_weight': 1, 'final_estimator__n_estimators': 200, 'final_estimator__subsample': 0.75}\n"
     ]
    }
   ],
   "source": [
    "model_stack = xgb.XGBClassifier(objective='multi:softmax', random_state=1)\n",
    "model = StackingClassifier(estimators=models, final_estimator=model_stack)\n",
    "max_depth =[2, 6, 8]\n",
    "learning_rate = [0.1, 0.01]\n",
    "n_estimators = [200,600,1000]\n",
    "subsample = [0.75, 1]\n",
    "colsample_bytree = [0.75, 1]\n",
    "min_child_weight= [0.5, 1]\n",
    "grid = dict(final_estimator__max_depth=max_depth,final_estimator__subsample=subsample,\n",
    "            final_estimator__colsample_bytree=colsample_bytree, final_estimator__min_child_weight=min_child_weight,\n",
    "            final_estimator__learning_rate=learning_rate, final_estimator__n_estimators=n_estimators)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid,\n",
    "                           n_jobs=-1, cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.890317 using {'final_estimator__var_smoothing': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model_stack =  GaussianNB()\n",
    "model = StackingClassifier(estimators=models, final_estimator=model_stack)\n",
    "var_smoothing= np.logspace(0,-9, num=5)\n",
    "grid = dict(final_estimator__var_smoothing=var_smoothing)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the proposed stacking ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stack =  SVC(C= 0.1, kernel='poly')\n",
    "model_ensemble = StackingClassifier(estimators=models, final_estimator=model_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the proposed stacking model and 5 base classifiers using 3-times repeated stratified 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8624 (0.0812)\n",
      "f1_macro: 0.8481 (0.0939)\n",
      "precision_macro: 0.8875 (0.0699)\n",
      "recall_macro: 0.8537 (0.0904)\n",
      "kappa_scorer: 0.7899 (0.1253)\n"
     ]
    }
   ],
   "source": [
    "model=model_knn\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8909 (0.0629)\n",
      "f1_macro: 0.8844 (0.0694)\n",
      "precision_macro: 0.9056 (0.0648)\n",
      "recall_macro: 0.8907 (0.0669)\n",
      "kappa_scorer: 0.8337 (0.0973)\n"
     ]
    }
   ],
   "source": [
    "model=model_svm\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8794 (0.0897)\n",
      "f1_macro: 0.8689 (0.0967)\n",
      "precision_macro: 0.9089 (0.0647)\n",
      "recall_macro: 0.8778 (0.0900)\n",
      "kappa_scorer: 0.8190 (0.1337)\n"
     ]
    }
   ],
   "source": [
    "model=model_nb\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8309 (0.0912)\n",
      "f1_macro: 0.8023 (0.1171)\n",
      "precision_macro: 0.8322 (0.1275)\n",
      "recall_macro: 0.8148 (0.1038)\n",
      "kappa_scorer: 0.7413 (0.1408)\n"
     ]
    }
   ],
   "source": [
    "model=model_rf\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8248 (0.1119)\n",
      "f1_macro: 0.8054 (0.1187)\n",
      "precision_macro: 0.8570 (0.1021)\n",
      "recall_macro: 0.8074 (0.1159)\n",
      "kappa_scorer: 0.7335 (0.1683)\n"
     ]
    }
   ],
   "source": [
    "model=model_xgb\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9236 (0.0530)\n",
      "f1_macro: 0.9149 (0.0634)\n",
      "precision_macro: 0.9263 (0.0612)\n",
      "recall_macro: 0.9222 (0.0619)\n",
      "kappa_scorer: 0.8841 (0.0817)\n"
     ]
    }
   ],
   "source": [
    "model = model_ensemble\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
