{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklvq import GLVQ\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data from Excel and creating initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data = pd.read_excel(r'https://github.com/DanialShirazi/delay-prediction/raw/main/Input%20Dataset.xlsx', sheet_name='dataset',index_col=0, engine='openpyxl')\n",
    "raw_data = excel_data.values[:,0:67]\n",
    "y = excel_data.label\n",
    "std_data = StandardScaler().fit_transform(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the optimal number of principal components for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.3018181818181819],\n",
       " [2, 0.1903030303030303],\n",
       " [3, 0.1333333333333333],\n",
       " [4, 0.1515151515151516],\n",
       " [5, 0.10909090909090913],\n",
       " [6, 0.11454545454545462],\n",
       " [7, 0.1260606060606061],\n",
       " [8, 0.1266666666666667],\n",
       " [9, 0.13212121212121208],\n",
       " [10, 0.13212121212121208],\n",
       " [11, 0.13818181818181818],\n",
       " [12, 0.1321212121212122],\n",
       " [13, 0.13818181818181818],\n",
       " [14, 0.13818181818181818],\n",
       " [15, 0.13818181818181818],\n",
       " [16, 0.13818181818181818],\n",
       " [17, 0.13818181818181818],\n",
       " [18, 0.14484848484848478],\n",
       " [19, 0.13818181818181818],\n",
       " [20, 0.13818181818181818]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_k_scores =[]\n",
    "for i in range (1,21):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "    data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "    data = data.assign(concrete=std_data[:,[65]])\n",
    "    data = data.assign(time=std_data[:,[66]])\n",
    "    model = SVC()\n",
    "    kernel = ['poly', 'rbf', 'sigmoid']\n",
    "    C = [ 1.0, 2.0, 3.0,5.0,10.0, 0.1, 0.01]\n",
    "    grid = dict(kernel=kernel,C=C)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                               cv=cv, scoring='accuracy',error_score=0)\n",
    "    grid_result = grid_search.fit(data, y)\n",
    "    pca_k_scores.append([i,(1-grid_result.best_score_)])\n",
    "pca_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3284848484848484,\n",
       " 0.1884848484848486,\n",
       " 0.18060606060606055,\n",
       " 0.18727272727272726,\n",
       " 0.16909090909090907,\n",
       " 0.18848484848484837,\n",
       " 0.21272727272727276,\n",
       " 0.19454545454545447,\n",
       " 0.19999999999999984,\n",
       " 0.20060606060606057,\n",
       " 0.19333333333333336,\n",
       " 0.20666666666666655,\n",
       " 0.22484848484848485,\n",
       " 0.21393939393939398,\n",
       " 0.21939393939393925,\n",
       " 0.23272727272727267,\n",
       " 0.22545454545454535,\n",
       " 0.20666666666666667,\n",
       " 0.20181818181818179,\n",
       " 0.22606060606060607]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_k_scores =[]\n",
    "for i in range (1,21):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "    data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "    data = data.assign(concrete=std_data[:,[65]])\n",
    "    data = data.assign(time=std_data[:,[66]])\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    n_estimators = [50, 100, 120, 200]\n",
    "    max_features = ['sqrt', 'log2']\n",
    "    max_depth = [2,6,8,10]\n",
    "    grid = dict(n_estimators=n_estimators,\n",
    "                max_features=max_features,max_depth=max_depth)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='accuracy',error_score=0)\n",
    "    grid_result = grid_search.fit(data, y)\n",
    "    pca_k_scores.append(1-grid_result.best_score_)\n",
    "pca_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38943562610229276,\n",
       " 0.17684784351451033,\n",
       " 0.14100529100529102,\n",
       " 0.16134038800705475,\n",
       " 0.13107583774250442,\n",
       " 0.12469135802469133,\n",
       " 0.12469135802469133,\n",
       " 0.12358024691358027,\n",
       " 0.14007054673721342,\n",
       " 0.1852380952380952,\n",
       " 0.17786596119929454,\n",
       " 0.17827160493827165,\n",
       " 0.17206349206349203,\n",
       " 0.18564373897707231,\n",
       " 0.18564373897707231,\n",
       " 0.18564373897707231,\n",
       " 0.18564373897707231,\n",
       " 0.1925573192239859,\n",
       " 0.1925573192239859,\n",
       " 0.1925573192239859]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_k_scores =[]\n",
    "for i in range (1,21):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "    data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "    data = data.assign(concrete=std_data[:,[65]])\n",
    "    data = data.assign(time=std_data[:,[66]])\n",
    "    model = GaussianNB()\n",
    "    var_smoothing= np.logspace(0,-9, num=5)\n",
    "    grid = dict(var_smoothing=var_smoothing)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                               cv=cv, scoring='f1_macro',error_score=0)\n",
    "    grid_result = grid_search.fit(data, y)\n",
    "    pca_k_scores.append(1-grid_result.best_score_)\n",
    "pca_k_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction with PCA and creating the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca_data = pca.fit_transform(std_data[:,0:65])\n",
    "pca.explained_variance_ratio_\n",
    "data = pd.DataFrame(pca_data,index=excel_data.index)\n",
    "data = data.assign(concrete=std_data[:,[65]])\n",
    "data = data.assign(time=std_data[:,[66]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters of conventional machine learning classifiers using grid search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.884374 using {'C': 1.0, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "C = [ 1.0, 2.0, 3.0, 5.0, 10.0, 0.1, 0.01]\n",
    "grid = dict(kernel=kernel,C=C)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.802257 using {'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "n_estimators = [50, 100, 120, 200]\n",
    "max_features = ['sqrt', 'log2']\n",
    "max_depth = [2,6,8,10]\n",
    "grid = dict(n_estimators=n_estimators,\n",
    "            max_features=max_features,max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.868924 using {'var_smoothing': 0.005623413251903491}\n"
     ]
    }
   ],
   "source": [
    "model =  GaussianNB()\n",
    "var_smoothing= np.logspace(0,-9, num=5)\n",
    "grid = dict(var_smoothing=var_smoothing)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters of shallow ANNs using grid search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.920882 using {'activation_params': {'beta': 1}, 'activation_type': 'swish', 'distance_type': 'squared-euclidean', 'solver_type': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "720 fits failed out of a total of 1800.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\models\\_base.py\", line 568, in fit\n",
      "    self._before_fit(X, y_index)\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\models\\_base.py\", line 527, in _before_fit\n",
      "    self._init_objective()\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\models\\_glvq.py\", line 315, in _init_objective\n",
      "    self.discriminant_params,\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\objectives\\_generalized_learning_objective.py\", line 71, in __init__\n",
      "    self.activation = activation_class(**activation_params)\n",
      "TypeError: Identity() takes no arguments\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\models\\_base.py\", line 568, in fit\n",
      "    self._before_fit(X, y_index)\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\models\\_base.py\", line 529, in _before_fit\n",
      "    self._init_solver()\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\models\\_base.py\", line 438, in _init_solver\n",
      "    solver_class = init_class(solvers, self.solver_type, self.valid_solvers)\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\_utils.py\", line 57, in init_class\n",
      "    parameter_class = package.import_from_string(class_type, valid_class_types)\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\solvers\\__init__.py\", line 31, in import_from_string\n",
      "    __name__, class_string, ALIASES, \"objective_type\", valid_strings\n",
      "  File \"C:\\Users\\dania\\anaconda3\\lib\\site-packages\\sklvq\\_utils.py\", line 50, in _import_from_string\n",
      "    raise ValueError(f\"Provided {param_name} is invalid.\")\n",
      "ValueError: Provided objective_type is invalid.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "model = GLVQ()\n",
    "distance_type= ['squared-euclidean', 'euclidean']\n",
    "activation_type= ['identity', 'sigmoid', 'soft+', 'swish']\n",
    "activation_params= [{'beta': beta} for beta in range(1, 4, 1)]\n",
    "solver_type=['sgd', 'wgd', 'adam', 'lbfgs', 'bfgs']\n",
    "grid= dict(\n",
    "distance_type=distance_type,\n",
    "    activation_type=activation_type,\n",
    "    activation_params=activation_params,\n",
    "    solver_type=solver_type)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.905291 using {'activation': 'tanh', 'alpha': 1, 'hidden_layer_sizes': 7, 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter=1000,  random_state=1)\n",
    "hidden_layer_sizes= [(7),(8),(9),(10)]\n",
    "activation= ['tanh', 'relu','identity','logistic']\n",
    "solver= ['sgd', 'adam','lbfgs']\n",
    "alpha= [0.0001, 0.1, 0.5, 1, 0.7]\n",
    "learning_rate= ['constant','adaptive','invscaling']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(iid=False, estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best architecture for proposed Deep-MLP-NN and Tuning its hyperparameters using grid search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        layer_2.append((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.926984 using {'activation': 'tanh', 'alpha': 1, 'hidden_layer_sizes': (8, 9), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#2layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_2\n",
    "activation= ['tanh', 'relu']\n",
    "solver= ['sgd', 'adam','lbfgs']\n",
    "alpha= [0.1, 1, 0.7]\n",
    "learning_rate= ['constant','adaptive','invscaling']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(iid=False, estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_3= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        for c in range(7,10):\n",
    "            layer_3.append((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.915309 using {'activation': 'tanh', 'alpha': 0.7, 'hidden_layer_sizes': (7, 7, 8), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#3layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_3\n",
    "activation= ['tanh', 'relu']\n",
    "solver= ['adam','lbfgs']\n",
    "alpha= [1, 0.7]\n",
    "learning_rate= ['constant','adaptive']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(iid=False, estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_4= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        for c in range(7,10):\n",
    "            for d in range(7,10):\n",
    "                layer_4.append((a,b,c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.938095 using {'activation': 'tanh', 'alpha': 0.7, 'hidden_layer_sizes': (8, 8, 8, 7), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#4layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_4\n",
    "activation= ['tanh', 'relu']\n",
    "solver= ['adam','lbfgs']\n",
    "alpha= [1, 0.7]\n",
    "learning_rate= ['constant','adaptive']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(iid=False, estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_5= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        for c in range(7,10):\n",
    "            for d in range(7,10):\n",
    "                 for e in range(7,10):\n",
    "                        layer_5.append((a,b,c,d,e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.935767 using {'activation': 'tanh', 'alpha': 0.7, 'hidden_layer_sizes': (8, 7, 9, 7, 7), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#5layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_5\n",
    "activation= ['tanh']\n",
    "solver= ['adam','lbfgs']\n",
    "alpha= [ 0.7]\n",
    "learning_rate= ['constant']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(iid=False, estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_6= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        for c in range(7,10):\n",
    "            for d in range(7,10):\n",
    "                 for e in range(7,10):\n",
    "                        for f in range(7,10):\n",
    "                            layer_6.append((a,b,c,d,e,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.937954 using {'activation': 'tanh', 'alpha': 0.7, 'hidden_layer_sizes': (8, 8, 8, 8, 8, 7), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#6layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_6\n",
    "activation= ['tanh']\n",
    "solver= ['adam']\n",
    "alpha= [ 0.7]\n",
    "learning_rate= ['constant']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(iid=False, estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(data, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ML/DL algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(C= 1.0, kernel='sigmoid')\n",
    "model_rf = RandomForestClassifier(random_state=1, max_depth=8 , max_features='sqrt', n_estimators=200)\n",
    "model_nb = GaussianNB(var_smoothing= 0.0056)\n",
    "model_xgb = xgb.XGBClassifier(objective='multi:softmax', colsample_bytree=1, learning_rate= 0.1,\n",
    "                              max_depth= 2, min_child_weight= 0.5, n_estimators= 2000, subsample= 0.75)\n",
    "model_mlp_1layer = MLPClassifier(max_iter=1000,random_state=1, activation= 'tanh', alpha= 1, hidden_layer_sizes= (7), learning_rate= 'constant', solver= 'adam' )\n",
    "model_mlp_2layer = MLPClassifier(max_iter=2000,random_state=1, activation= 'tanh', alpha= 1, hidden_layer_sizes= (8, 9), learning_rate= 'constant', solver= 'adam' )\n",
    "model_mlp_3layer = MLPClassifier(max_iter=2000,random_state=1, activation= 'tanh', alpha= 0.7, hidden_layer_sizes= (7, 7, 8), learning_rate= 'constant', solver= 'adam' )\n",
    "model_mlp_4layer = MLPClassifier(max_iter=2000,random_state=1, activation= 'tanh', alpha= 0.7, hidden_layer_sizes= (8, 8, 8, 7), learning_rate= 'constant', solver= 'adam' )\n",
    "model_mlp_5layer = MLPClassifier(max_iter=2000,random_state=1, activation= 'tanh', alpha= 0.7, hidden_layer_sizes= (8, 7, 9, 7, 7), learning_rate= 'constant', solver= 'adam' )\n",
    "model_mlp_6layer = MLPClassifier(max_iter=2000,random_state=1, activation= 'tanh', alpha= 0.7, hidden_layer_sizes= (8, 8, 8, 8, 8, 7), learning_rate= 'constant', solver= 'adam' )\n",
    "model_glvq = GLVQ(activation_params= {'beta': 1}, activation_type= 'swish', distance_type= 'squared-euclidean', solver_type= 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the proposed DL model and 5 shallow classifiers using 3-times repeated stratified 5-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8909 (0.0629)\n",
      "f1_macro: 0.8844 (0.0694)\n",
      "precision_macro: 0.9056 (0.0648)\n",
      "recall_macro: 0.8907 (0.0669)\n",
      "kappa_scorer: 0.8337 (0.0973)\n"
     ]
    }
   ],
   "source": [
    "model=model_svm\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8794 (0.0897)\n",
      "f1_macro: 0.8689 (0.0967)\n",
      "precision_macro: 0.9089 (0.0647)\n",
      "recall_macro: 0.8778 (0.0900)\n",
      "kappa_scorer: 0.8190 (0.1337)\n"
     ]
    }
   ],
   "source": [
    "model=model_nb\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8309 (0.0912)\n",
      "f1_macro: 0.8023 (0.1171)\n",
      "precision_macro: 0.8322 (0.1275)\n",
      "recall_macro: 0.8148 (0.1038)\n",
      "kappa_scorer: 0.7413 (0.1408)\n"
     ]
    }
   ],
   "source": [
    "model=model_rf\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8248 (0.1119)\n",
      "f1_macro: 0.8054 (0.1187)\n",
      "precision_macro: 0.8570 (0.1021)\n",
      "recall_macro: 0.8074 (0.1159)\n",
      "kappa_scorer: 0.7335 (0.1683)\n"
     ]
    }
   ],
   "source": [
    "model=model_xgb\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLVQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9303 (0.0649)\n",
      "f1_macro: 0.9209 (0.0770)\n",
      "precision_macro: 0.9393 (0.0543)\n",
      "recall_macro: 0.9315 (0.0664)\n",
      "kappa_scorer: 0.8951 (0.0978)\n"
     ]
    }
   ],
   "source": [
    "model=model_glvq\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9188 (0.0676)\n",
      "f1_macro: 0.9053 (0.0850)\n",
      "precision_macro: 0.9311 (0.0616)\n",
      "recall_macro: 0.9111 (0.0825)\n",
      "kappa_scorer: 0.8758 (0.1048)\n"
     ]
    }
   ],
   "source": [
    "model=model_mlp_1layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Hidden layer deep MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9364 (0.0921)\n",
      "f1_macro: 0.9270 (0.1064)\n",
      "precision_macro: 0.9478 (0.0800)\n",
      "recall_macro: 0.9315 (0.0998)\n",
      "kappa_scorer: 0.9021 (0.1425)\n"
     ]
    }
   ],
   "source": [
    "model=model_mlp_2layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Hidden layer deep MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9242 (0.0642)\n",
      "f1_macro: 0.9153 (0.0743)\n",
      "precision_macro: 0.9337 (0.0649)\n",
      "recall_macro: 0.9185 (0.0699)\n",
      "kappa_scorer: 0.8844 (0.0985)\n"
     ]
    }
   ],
   "source": [
    "model=model_mlp_3layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed 4 hidden layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9436 (0.0676)\n",
      "f1_macro: 0.9381 (0.0773)\n",
      "precision_macro: 0.9585 (0.0519)\n",
      "recall_macro: 0.9407 (0.0709)\n",
      "kappa_scorer: 0.9136 (0.1035)\n"
     ]
    }
   ],
   "source": [
    "model=model_mlp_4layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Hidden layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9442 (0.0564)\n",
      "f1_macro: 0.9358 (0.0679)\n",
      "precision_macro: 0.9533 (0.0459)\n",
      "recall_macro: 0.9407 (0.0640)\n",
      "kappa_scorer: 0.9150 (0.0865)\n"
     ]
    }
   ],
   "source": [
    "model=model_mlp_5layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Hidden layer deep MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9436 (0.0676)\n",
      "f1_macro: 0.9380 (0.0773)\n",
      "precision_macro: 0.9563 (0.0532)\n",
      "recall_macro: 0.9426 (0.0699)\n",
      "kappa_scorer: 0.9139 (0.1034)\n"
     ]
    }
   ],
   "source": [
    "model=model_mlp_6layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed model without parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8727 (0.0713)\n",
      "f1_macro: 0.8446 (0.0738)\n",
      "precision_macro: 0.8893 (0.0608)\n",
      "recall_macro: 0.8593 (0.0551)\n",
      "kappa_scorer: 0.7694 (0.1189)\n"
     ]
    }
   ],
   "source": [
    "model=MLPClassifier()\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed model without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8048 (0.0819)\n",
      "f1_macro: 0.7793 (0.0898)\n",
      "precision_macro: 0.8385 (0.0894)\n",
      "recall_macro: 0.7833 (0.0862)\n",
      "kappa_scorer: 0.7004 (0.1256)\n"
     ]
    }
   ],
   "source": [
    "model=model_mlp_4layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, std_data, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, std_data, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, std_data, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, std_data, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, std_data, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed model without projrct specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8370 (0.0805)\n",
      "f1_macro: 0.8144 (0.0918)\n",
      "precision_macro: 0.8678 (0.0728)\n",
      "recall_macro: 0.8222 (0.0877)\n",
      "kappa_scorer: 0.7517 (0.1226)\n"
     ]
    }
   ],
   "source": [
    "model=model_mlp_4layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, data_risk, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data_risk, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data_risk, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data_risk, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, data_risk, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
